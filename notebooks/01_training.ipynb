{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2jji3LQ0LAp"
   },
   "source": [
    "# Deploy DL Model on Web & Mobile Using Pyotrch\n",
    "---\n",
    "## Milestone 1: Build an image classifier\n",
    "## Partial Solutions Notebook\n",
    "---\n",
    "#### Date updated:  12-September-2021\n",
    "#### Author:  Nidhin Pattaniyil & Reshama Shaikh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_dataset.ipynb\t     __pycache__\r\n",
      "01_train.py\t\t     ant_transfer_learning_tutorial.ipynb\r\n",
      "01_train_out.txt\t     artifacts\r\n",
      "01_training.ipynb\t     data\r\n",
      "01_training__output.ipynb    milestone1_partial_solution_3classes.ipynb\r\n",
      "01_training_raw_food.ipynb   requirements.txt\r\n",
      "02_torch_optimization.ipynb  utility.py\r\n",
      "Untitled.ipynb\t\t     wandb\r\n",
      "Untitled1.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import date\n",
    "# from datetime import datetime\n",
    "import datetime\n",
    "import plotly.figure_factory as ff\n",
    "import wandb\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import pytorch_lightning as pl\n",
    "import flash\n",
    "import flash.image\n",
    "from flash.core.data.utils import download_data\n",
    "# from flash.image import ImageClassificationData, ImageClassifier\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "#from sklearn.model_selection import train_test_split \n",
    "#from flash.image.classification.adapters import TRAINING_STRATEGIES\n",
    "# from flash.image.classification.backbones import IMAGE_CLASSIFIER_BACKBONES\n",
    "# from flash.core.classification import Probabilities\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import flash\n",
    "from flash.core.data.data_source import DefaultDataKeys\n",
    "from flash.core.data.transforms import ApplyToKeys, merge_transforms\n",
    "# from flash.image import ImageClassificationData, ImageClassifier\n",
    "# from flash.image.classification.transforms import default_transforms\n",
    "import flash.core.integrations.fiftyone\n",
    "import flash.core.classification \n",
    "import fiftyone as fo\n",
    "import warnings\n",
    "import itertools\n",
    "import timeit\n",
    "import json\n",
    "import torchinfo\n",
    "import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flash.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_name = 'resnet34'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_fiftyone_dataset(df:pd.DataFrame, name=\"test_df\"):\n",
    "#     samples = []\n",
    "    \n",
    "#     if fo.dataset_exists(name):\n",
    "#         fo.delete_dataset(name)\n",
    "#     for record in df.to_dict(orient='records'):\n",
    "#         sample = fo.Sample(\n",
    "#                 filepath=record['file_path'],\n",
    "#                 ground_truth=fo.Classification(label=record['label']),\n",
    "#             )\n",
    "        \n",
    "#         sample['ground_truth'] = fo.Classification(label=record['label'])\n",
    "#         samples.append(sample)\n",
    "#     dataset = fo.Dataset(name)\n",
    "#     dataset.add_samples(samples)\n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LRWAJYt4jv8"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "current_date = datetime.date.today()\n",
    "print(\"Today's date:\", current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1Y5mbjxwm_-"
   },
   "outputs": [],
   "source": [
    "now1 = datetime.datetime.now()\n",
    "\n",
    "start_time = now1.strftime(\"%H:%M:%S\")\n",
    "print(\"Start Time =\", start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightning-flash==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the backbones available for ImageClassifier\n",
    "backbones = flash.image.ImageClassifier.available_backbones()\n",
    "\n",
    "# print the backbones\n",
    "#print(backbones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://lp-prod-resources.s3-us-west-2.amazonaws.com/other/Deploying+a+Deep+Learning+Model+on+Web+and+Mobile+Applications+Using+TensorFlow/Food+101+-+Data+Subset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_data(\"https://pl-flash-data.s3.amazonaws.com/hymenoptera_data.zip\", 'data/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/food-101-subset/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob(f\"{data_dir}/*/*.jpg\")\n",
    "# df = pd.DataFrame({'file_path':files})\n",
    "# df['label_name'] = df['file_path'].apply(lambda x:x.split(\"/\")[-2])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/food-101/meta/train.txt\",header=None,names=['file_path'])\n",
    "df['label_name'] = df['file_path'].apply(lambda x:x.split(\"/\")[-2])\n",
    "\n",
    "df['file_path'] = \"data/food-101/images/\" + df[\"file_path\"]+\".jpg\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder.fit(df['label_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = label_encoder.transform(df['label_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv(\"data/food-101/meta/test.txt\",header=None,names=['file_path'])\n",
    "df_eval['label_name'] = df_eval['file_path'].apply(lambda x:x.split(\"/\")[-2])\n",
    "df_eval['file_path'] = \"data/food-101/images/\" + df_eval[\"file_path\"]+\".jpg\"\n",
    "df_eval['label'] = label_encoder.transform(df_eval['label_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls data/food-101/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset; 85% for training and 15 % for testing\n",
    "df_train, df_test = sklearn.model_selection.train_test_split(df, test_size=0.15, stratify=df['label'],shuffle = True) \n",
    "\n",
    "# split the training dataset: 80% for actual training and 20% for validation\n",
    "df_train, df_val = sklearn.model_selection.train_test_split(df_train, test_size=0.20, random_state=1 , stratify=df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ({\"train\": len(df_train), \"test\":len(df_test), \"val\":len(df_val) ,\"eval\": len(df_eval)  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_transforms = flash.image.classification.transforms.default_transforms((224, 224))\n",
    "default_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_tensor_transform = ApplyToKeys(\n",
    "    DefaultDataKeys.INPUT,\n",
    "    T.Compose([T.RandomHorizontalFlip(), T.ColorJitter(), T.RandomAutocontrast(), T.RandomPerspective()]),\n",
    ")\n",
    "\n",
    "new_transforms = merge_transforms(default_transforms, {\"post_tensor_transform\": post_tensor_transform})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule = ImageClassificationData.from_data_frame(\n",
    "#     \"file_path\",\n",
    "#     \"label\",\n",
    "#     train_data_frame=df_train,\n",
    "#     val_data_frame=df_val,\n",
    "#     test_data_frame=df_test,\n",
    "#     train_transform=new_transforms\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.delete_non_persistent_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████████| 0/0 [450.6us elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 0/0 [463.0us elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 0/0 [373.8us elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 0/0 [364.7us elapsed, ? remaining, ? samples/s] \n"
     ]
    }
   ],
   "source": [
    "# train_dataset = create_fiftyone_dataset (df_train,\"train\")\n",
    "# val_dataset = create_fiftyone_dataset (df_val,\"validation\") \n",
    "# test_dataset = create_fiftyone_dataset (df_test,\"test\")\n",
    "# eval_dataset = create_fiftyone_dataset (df_eval,\"eval\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??fo.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dataset has no field 'ground_truth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-af2e3dcb0f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m datamodule = flash.image.ImageClassificationData.from_fiftyone(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#train_transform=new_transforms,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_module.py\u001b[0m in \u001b[0;36mfrom_fiftyone\u001b[0;34m(cls, train_dataset, val_dataset, test_dataset, predict_dataset, train_transform, val_transform, test_transform, predict_transform, data_fetcher, preprocess, val_split, batch_size, num_workers, **preprocess_kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             )\n\u001b[1;32m   1254\u001b[0m         \"\"\"\n\u001b[0;32m-> 1255\u001b[0;31m         return cls.from_data_source(\n\u001b[0m\u001b[1;32m   1256\u001b[0m             \u001b[0mDefaultDataSources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFIFTYONE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_module.py\u001b[0m in \u001b[0;36mfrom_data_source\u001b[0;34m(cls, data_source, train_data, val_data, test_data, predict_data, train_transform, val_transform, test_transform, predict_transform, data_fetcher, preprocess, val_split, batch_size, num_workers, sampler, **preprocess_kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdata_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source_of_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         train_dataset, val_dataset, test_dataset, predict_dataset = data_source.to_datasets(\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_source.py\u001b[0m in \u001b[0;36mto_datasets\u001b[0;34m(self, train_data, val_data, test_data, predict_data)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorresponding\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunningStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAINING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunningStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALIDATING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunningStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTESTING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_source.py\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[0;34m(self, data, running_stage)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"dataset\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: This was DATASET_KEY before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmock_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_source.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, data, dataset)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrequires\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fiftyone\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSampleCollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mlabel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_field_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_source.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0mlabel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_field_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_field\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected field '{self.label_field}' to have type {self.label_cls}; found {label_type}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/fiftyone/core/collections.py\u001b[0m in \u001b[0;36m_get_label_field_type\u001b[0;34m(self, field_name)\u001b[0m\n\u001b[1;32m   6998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfield_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6999\u001b[0m             \u001b[0mftype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"frame field\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_frame_field\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"field\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7000\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   7001\u001b[0m                 \u001b[0;34m\"%s has no %s '%s'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7002\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mftype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dataset has no field 'ground_truth'"
     ]
    }
   ],
   "source": [
    "# datamodule = flash.image.ImageClassificationData.from_fiftyone(\n",
    "#     train_dataset=train_dataset,\n",
    "#     val_dataset=val_dataset,\n",
    "#     test_dataset=test_dataset,\n",
    "#     train_transform=new_transforms,\n",
    "#      batch_size=64,\n",
    "#      num_workers=16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data_dir:str)->flash.core.data.data_module.DataModule :\n",
    "    \n",
    "    df_train = pd.read_parquet(f\"{data_dir}/df_train.parquet\" )\n",
    "    df_test = pd.read_parquet(f\"{data_dir}/df_test.parquet\")\n",
    "    df_val = pd.read_parquet(f\"{data_dir}/df_val.parquet\")\n",
    "    df_eval = pd.read_parquet(f\"{data_dir}/df_eval.parquet\")\n",
    "    \n",
    "    \n",
    "#     train_dataset = utility.create_fiftyone_dataset (df_train,\"train\")\n",
    "#     val_dataset = utility.create_fiftyone_dataset (df_val,\"validation\") \n",
    "#     test_dataset = utility.create_fiftyone_dataset (df_test,\"test\")\n",
    "\n",
    "    train_dataset = create_fiftyone_dataset (df_train,\"train\")\n",
    "    val_dataset = create_fiftyone_dataset (df_val,\"validation\") \n",
    "    test_dataset = create_fiftyone_dataset (df_test,\"test\")\n",
    "    \n",
    "    new_transforms = utility.image_transforms()\n",
    "    \n",
    "    datamodule = flash.image.ImageClassificationData.from_fiftyone(\n",
    "        train_dataset=train_dataset,\n",
    "#         val_dataset=val_dataset,\n",
    "#         test_dataset=test_dataset,\n",
    "        # train_transform=new_transforms,\n",
    "    )\n",
    "    \n",
    "    return datamodule , df_eval\n",
    "    \n",
    "#    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████████| 0/0 [403.7us elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 0/0 [582.1us elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 0/0 [665.9us elapsed, ? remaining, ? samples/s] \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dataset has no field 'ground_truth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-90126c5495b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatamodule\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdf_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"artifacts/data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-fd40731033d3>\u001b[0m in \u001b[0;36mprepare_dataset\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnew_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     datamodule = flash.image.ImageClassificationData.from_fiftyone(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#         val_dataset=val_dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_module.py\u001b[0m in \u001b[0;36mfrom_fiftyone\u001b[0;34m(cls, train_dataset, val_dataset, test_dataset, predict_dataset, train_transform, val_transform, test_transform, predict_transform, data_fetcher, preprocess, val_split, batch_size, num_workers, **preprocess_kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             )\n\u001b[1;32m   1254\u001b[0m         \"\"\"\n\u001b[0;32m-> 1255\u001b[0;31m         return cls.from_data_source(\n\u001b[0m\u001b[1;32m   1256\u001b[0m             \u001b[0mDefaultDataSources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFIFTYONE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_module.py\u001b[0m in \u001b[0;36mfrom_data_source\u001b[0;34m(cls, data_source, train_data, val_data, test_data, predict_data, train_transform, val_transform, test_transform, predict_transform, data_fetcher, preprocess, val_split, batch_size, num_workers, sampler, **preprocess_kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdata_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source_of_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         train_dataset, val_dataset, test_dataset, predict_dataset = data_source.to_datasets(\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_source.py\u001b[0m in \u001b[0;36mto_datasets\u001b[0;34m(self, train_data, val_data, test_data, predict_data)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorresponding\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunningStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAINING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunningStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALIDATING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunningStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTESTING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_source.py\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[0;34m(self, data, running_stage)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"dataset\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: This was DATASET_KEY before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmock_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_source.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, data, dataset)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrequires\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fiftyone\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSampleCollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mlabel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_field_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/flash/core/data/data_source.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0mlabel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_field_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_field\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected field '{self.label_field}' to have type {self.label_cls}; found {label_type}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.8/site-packages/fiftyone/core/collections.py\u001b[0m in \u001b[0;36m_get_label_field_type\u001b[0;34m(self, field_name)\u001b[0m\n\u001b[1;32m   6998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfield_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6999\u001b[0m             \u001b[0mftype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"frame field\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_frame_field\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"field\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7000\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   7001\u001b[0m                 \u001b[0;34m\"%s has no %s '%s'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7002\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mftype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dataset has no field 'ground_truth'"
     ]
    }
   ],
   "source": [
    "datamodule , df_eval = prepare_dataset(\"artifacts/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = \"data/food-101-subset/images/apple_pie/1005649.jpg\"\n",
    "strategy=\"dp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input_size = (1, 3, 224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_inference(model,device='cpu'):\n",
    "    model = model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.to(device)\n",
    "        predictions = model.predict(sample_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name:str, epochs = 2, unfreeze_epoch = 5 ,num_iterations=10, df_eval=df_eval  ):\n",
    "    model = flash.image.ImageClassifier(num_classes=datamodule.num_classes,backbone=model_name)\n",
    "    print (f\"Model Spec: {model_name}\")\n",
    "    print(model)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print (\"Model Summary\")\n",
    "    \n",
    "    model_summary = torchinfo.summary(model, input_size=sample_input_size, verbose=0)\n",
    "    print (model_summary)\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    \n",
    "    trainer = flash.Trainer(max_epochs=epochs, gpus=torch.cuda.device_count() , strategy=strategy)\n",
    "\n",
    "    \n",
    "    \n",
    "    trainer.finetune(model, datamodule=datamodule\n",
    "                 , strategy=flash.core.finetuning.FreezeUnfreeze(unfreeze_epoch=unfreeze_epoch) )\n",
    "    \n",
    "    \n",
    "    metrics_test = trainer.test(model, datamodule=datamodule)\n",
    "    print (metrics_test)\n",
    "\n",
    "    \n",
    "    metrics_val =trainer.validate(model, datamodule=datamodule)\n",
    "    print(metrics_val)\n",
    "    \n",
    "    artifact_model_path = f\"artifacts/model_{model_name}.pt\"\n",
    "    trainer.save_checkpoint(artifact_model_path)\n",
    "\n",
    "    model = flash.image.ImageClassifier.load_from_checkpoint(artifact_model_path)\n",
    "    \n",
    "    time_gpu = timeit.timeit(lambda: time_inference (model,device='cuda:0') ,number=num_iterations   ) \n",
    "    time_cpu = timeit.timeit(lambda: time_inference (model,device='cpu') ,number=num_iterations   ) \n",
    "    \n",
    "    \n",
    "    # eval dataset accuracy\n",
    "    eval_dataset = create_fiftyone_dataset (df_eval,\"eval\")\n",
    "    datamodule_eval = flash.image.ImageClassificationData.from_fiftyone(predict_dataset=eval_dataset)\n",
    "    predictions = trainer.predict(model, datamodule=datamodule_eval) # datamodule_predict\n",
    "    predictions = list(itertools.chain.from_iterable(predictions))  # flatten batches\n",
    "    y_proba = predictions\n",
    "    y_pred = np.argmax(y_proba, axis=1)\n",
    "    y_true = df_test['label']\n",
    "\n",
    "    eval_accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    \n",
    "    \n",
    "    res = {**metrics_test[0], **metrics_val[0]}\n",
    "    res['time_cpu'] = time_cpu\n",
    "    res['time_gpu'] = time_gpu\n",
    "    res['eval_accuracy'] = eval_accuracy\n",
    "    \n",
    "    res['params_total'] = model_summary.total_params\n",
    "    res['params_trainable'] = model_summary.trainable_params\n",
    "    \n",
    "\n",
    "\n",
    "    model_metrics[model_name] = res\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 30\n",
    "unfreeze_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = flash.Trainer(max_epochs=max_epochs, gpus=torch.cuda.device_count(), strategy=strategy  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vgg19'\n",
    "model = train_model(model_name=model_name, epochs = max_epochs, unfreeze_epoch = unfreeze_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model_name='resnet50', epochs = max_epochs, unfreeze_epoch = unfreeze_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model_name='mobilenet_v2', epochs = max_epochs, unfreeze_epoch = unfreeze_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model_name='mobilenetv3_small_100', epochs = max_epochs, unfreeze_epoch = unfreeze_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"artifacts/model_metrics.json\") as f:\n",
    "    payload = json.dumps(model_metrics)\n",
    "    f.write(payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(\"artifacts/data/df_train.parquet\")\n",
    "df_test.to_parquet(\"artifacts/data/df_test.parquet\")\n",
    "df_val.to_parquet(\"artifacts/data/df_val.parquet\")\n",
    "df_eval.to_parquet(\"artifacts/data/adf_eval.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "artifact_model_path = f\"artifacts/model_{model_name}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = flash.image.ImageClassifier.load_from_checkpoint(artifact_model_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary = torchinfo.summary(model, input_size=sample_input_size, verbose=0)\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.serializer = flash.core.classification.Probabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\"data/food-101-subset/images/apple_pie/1005649.jpg\")\n",
    "predictions\n",
    "#label_encoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted ( zip (label_encoder.classes_, predictions[0]), key= lambda x:x[1] ,reverse =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule_predict = ImageClassificationData.from_data_frame(\n",
    "#     \"file_path\",\n",
    "#     \"label\",\n",
    "#     test_data_frame=df_test,\n",
    "#     predict_transform=default_transforms\n",
    "# )\n",
    "# datamodule_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?flash.core.classification.PredsClassificationSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.serializer = flash.core.classification.PredsClassificationSerializer()\n",
    "# fo_predict = create_fiftyone_dataset(df_test,\"predict\")\n",
    "# datamodule_predict = ImageClassificationData.from_fiftyone(fo_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.serializer = flash.core.classification.FiftyOneLabels(return_filepath=False, labels=label_encoder.classes_)  # output FiftyOne format\n",
    "fo_predict = create_fiftyone_dataset(df_eval,\"predict\")\n",
    "datamodule_predict = flash.image.ImageClassificationData.from_fiftyone(predict_dataset=fo_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(model, datamodule=datamodule_predict) # datamodule_predict\n",
    "predictions = list(itertools.chain.from_iterable(predictions))  # flatten batches\n",
    "\n",
    "fo_predict.set_values(\"predictions\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fo_predict.evaluate_classifications(\"predictions\", gt_field=\"ground_truth\", eval_key=\"eval\")\n",
    "results.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = results.plot_confusion_matrix(classes=label_encoder.classes_)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Visualize results in the App\n",
    "session = fo.launch_app(fo_predict, auto=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.open_tab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ip a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot = results.plot_confusion_matrix(classes=label_encoder.classes_)\n",
    "plot.show(height=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to session\n",
    "#session.plots.attach(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: block execution until App is closed\n",
    "# session.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.serializer = flash.core.classification.Probabilities()\n",
    "\n",
    "predictions = trainer.predict(model,datamodule=datamodule_predict)\n",
    "predictions = list(itertools.chain.from_iterable(predictions))  # flatten batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_proba = model.predict(list ( df_test['file_path'] ) )\n",
    "# y_pred = np.argmax(y_proba, axis=1)\n",
    "# y_true = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = predictions\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "y_true = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/60860121/plotly-how-to-make-an-annotated-confusion-matrix-using-a-heatmap\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "cm_labels = label_encoder.classes_\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true=y_true, y_pred = y_pred ,\n",
    "    #normalize = 'true',\n",
    "    display_labels=cm_labels,\n",
    "    xticks_rotation='vertical',\n",
    "    ax=ax\n",
    ")\n",
    "disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = \"data/food-101-subset/images/apple_pie/1005649.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 9 -n 5\n",
    "time_inference (model,device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 9 -n 5\n",
    "time_inference (model,device='cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk6M8HvofvTR"
   },
   "source": [
    "# Get Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWPA6uYlUyBV"
   },
   "outputs": [],
   "source": [
    "! du -h artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbIPxgoN3zvd"
   },
   "outputs": [],
   "source": [
    "!ls artifacts/ -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bILr-eFU-wUG"
   },
   "source": [
    "# Compare Models\n",
    "\n",
    "- Dataset:  Food\n",
    "- Classes: 3\n",
    "- Total images: 3000\n",
    "- Batch size: 32\n",
    "\n",
    "| Model  | Trainable Params| Non-trainable Params | Time (hh:mm:ss) [a]| Accuracy | Epochs | Model Size [b]\n",
    "|---|---:|---:|---:|---:| ---:|---:|\n",
    "| VGG19| 528,387   | 20,024,384 | 00:00:48 | 96.8% | 3 | 83M\n",
    "| ResNet50   | xxx   | xxx |  xx:xx:xx | xx.x% | 3 | xxM\n",
    "| MobileNetV2  | xxx  | xxx |   xx:xx:xx | xx.x% | 3 | xxM\n",
    "| ResNet50_ft [c]  | xxx  | xxx | xx:xx:xx   | xx.x% | xx | xxM\n",
    "\n",
    "NOTES:  \n",
    "- [a] If wall clock time < CPU time, then you're executing a program in parallel.\n",
    "- [b] model size is size of output file\n",
    "- [c] ft = fine-tuned; time 2min 31s; 3min 59s; epochs 9+5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CU9ACHvSIEnZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVz7Xf40tPPP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh76dgMeVIDD"
   },
   "source": [
    "# Download Assets\n",
    "download model and classes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqxTNOVCoHCc"
   },
   "outputs": [],
   "source": [
    "#!zip -r artifacts/artifacts.zip {PROJECT_NAME}/artifacts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63KIL2HndL-c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.download(str(str(PROJECT_NAME)+\"/artifacts/artifacts.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVrj_UAD-xDr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "milestone1_partial_solution_3classes.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "rapids-gpu.0-18.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/rapids-gpu.0-18:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:pt]",
   "language": "python",
   "name": "conda-env-pt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
