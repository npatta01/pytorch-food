{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2jji3LQ0LAp"
   },
   "source": [
    "# Deploy DL Model on Web & Mobile Using Pyotrch\n",
    "---\n",
    "## Milestone 1: Build an image classifier\n",
    "## Partial Solutions Notebook\n",
    "---\n",
    "#### Date updated:  12-September-2021\n",
    "#### Author:  Nidhin Pattaniyil & Reshama Shaikh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import date\n",
    "# from datetime import datetime\n",
    "import datetime\n",
    "import plotly.figure_factory as ff\n",
    "import wandb\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import pytorch_lightning as pl\n",
    "import flash\n",
    "import flash.image\n",
    "from flash.core.data.utils import download_data\n",
    "# from flash.image import ImageClassificationData, ImageClassifier\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "#from sklearn.model_selection import train_test_split \n",
    "#from flash.image.classification.adapters import TRAINING_STRATEGIES\n",
    "# from flash.image.classification.backbones import IMAGE_CLASSIFIER_BACKBONES\n",
    "# from flash.core.classification import Probabilities\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import flash\n",
    "from flash.core.data.data_source import DefaultDataKeys\n",
    "from flash.core.data.transforms import ApplyToKeys, merge_transforms\n",
    "# from flash.image import ImageClassificationData, ImageClassifier\n",
    "# from flash.image.classification.transforms import default_transforms\n",
    "import flash.core.integrations.fiftyone\n",
    "import flash.core.classification \n",
    "import fiftyone as fo\n",
    "import warnings\n",
    "import itertools\n",
    "import timeit\n",
    "import json\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flash.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_name = 'resnet34'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fiftyone_dataset(df:pd.DataFrame, name=\"test_df\"):\n",
    "    samples = []\n",
    "    \n",
    "    if fo.dataset_exists(name):\n",
    "        fo.delete_dataset(name)\n",
    "    for record in df.to_dict(orient='records'):\n",
    "        samples.append(\n",
    "            fo.Sample(\n",
    "                filepath=record['file_path'],\n",
    "                ground_truth=fo.Classification(label=record['label_name']),\n",
    "            )\n",
    "        )\n",
    "    dataset = fo.Dataset(name)\n",
    "    dataset.add_samples(samples)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LRWAJYt4jv8"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "current_date = datetime.date.today()\n",
    "print(\"Today's date:\", current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1Y5mbjxwm_-"
   },
   "outputs": [],
   "source": [
    "now1 = datetime.datetime.now()\n",
    "\n",
    "start_time = now1.strftime(\"%H:%M:%S\")\n",
    "print(\"Start Time =\", start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightning-flash==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the backbones available for ImageClassifier\n",
    "backbones = flash.image.ImageClassifier.available_backbones()\n",
    "\n",
    "# print the backbones\n",
    "#print(backbones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://lp-prod-resources.s3-us-west-2.amazonaws.com/other/Deploying+a+Deep+Learning+Model+on+Web+and+Mobile+Applications+Using+TensorFlow/Food+101+-+Data+Subset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_data(\"https://pl-flash-data.s3.amazonaws.com/hymenoptera_data.zip\", 'data/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/food-101-subset/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/food-101-subset/images/caesar_salad/19219...</td>\n",
       "      <td>caesar_salad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/food-101-subset/images/caesar_salad/32695...</td>\n",
       "      <td>caesar_salad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/food-101-subset/images/caesar_salad/37647...</td>\n",
       "      <td>caesar_salad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/food-101-subset/images/caesar_salad/28502...</td>\n",
       "      <td>caesar_salad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/food-101-subset/images/caesar_salad/13516...</td>\n",
       "      <td>caesar_salad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path    label_name\n",
       "0  data/food-101-subset/images/caesar_salad/19219...  caesar_salad\n",
       "1  data/food-101-subset/images/caesar_salad/32695...  caesar_salad\n",
       "2  data/food-101-subset/images/caesar_salad/37647...  caesar_salad\n",
       "3  data/food-101-subset/images/caesar_salad/28502...  caesar_salad\n",
       "4  data/food-101-subset/images/caesar_salad/13516...  caesar_salad"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# files = glob.glob(f\"{data_dir}/*/*.jpg\")\n",
    "# df = pd.DataFrame({'file_path':files})\n",
    "# df['label_name'] = df['file_path'].apply(lambda x:x.split(\"/\")[-2])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/food-101/meta/train.txt\",header=None,names=['file_path'])\n",
    "df['label_name'] = df['file_path'].apply(lambda x:x.split(\"/\")[-2])\n",
    "\n",
    "df['file_path'] = \"data/food-101/images/\" + df[\"file_path\"]+\".jpg\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/food-101/images/apple_pie/1005649.jpg</td>\n",
       "      <td>apple_pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/food-101/images/apple_pie/1014775.jpg</td>\n",
       "      <td>apple_pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/food-101/images/apple_pie/1026328.jpg</td>\n",
       "      <td>apple_pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/food-101/images/apple_pie/1028787.jpg</td>\n",
       "      <td>apple_pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/food-101/images/apple_pie/1043283.jpg</td>\n",
       "      <td>apple_pie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file_path label_name\n",
       "0  data/food-101/images/apple_pie/1005649.jpg  apple_pie\n",
       "1  data/food-101/images/apple_pie/1014775.jpg  apple_pie\n",
       "2  data/food-101/images/apple_pie/1026328.jpg  apple_pie\n",
       "3  data/food-101/images/apple_pie/1028787.jpg  apple_pie\n",
       "4  data/food-101/images/apple_pie/1043283.jpg  apple_pie"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.fit(df['label_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = label_encoder.transform(df['label_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.read_csv(\"data/food-101/meta/test.txt\",header=None,names=['file_path'])\n",
    "df_eval['label_name'] = df_eval['file_path'].apply(lambda x:x.split(\"/\")[-2])\n",
    "df_eval['file_path'] = \"data/food-101/images/\" + df_eval[\"file_path\"]+\".jpg\"\n",
    "df_eval['label'] = label_encoder.transform(df_eval['label_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls data/food-101/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/food-101/images/apple_pie/1011328.jpg</td>\n",
       "      <td>apple_pie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/food-101/images/apple_pie/101251.jpg</td>\n",
       "      <td>apple_pie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/food-101/images/apple_pie/1034399.jpg</td>\n",
       "      <td>apple_pie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/food-101/images/apple_pie/103801.jpg</td>\n",
       "      <td>apple_pie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/food-101/images/apple_pie/1038694.jpg</td>\n",
       "      <td>apple_pie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file_path label_name  label\n",
       "0  data/food-101/images/apple_pie/1011328.jpg  apple_pie      0\n",
       "1   data/food-101/images/apple_pie/101251.jpg  apple_pie      0\n",
       "2  data/food-101/images/apple_pie/1034399.jpg  apple_pie      0\n",
       "3   data/food-101/images/apple_pie/103801.jpg  apple_pie      0\n",
       "4  data/food-101/images/apple_pie/1038694.jpg  apple_pie      0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset; 85% for training and 15 % for testing\n",
    "df_train, df_test = sklearn.model_selection.train_test_split(df, test_size=0.15, stratify=df['label'],shuffle = True) \n",
    "\n",
    "# split the training dataset: 80% for actual training and 20% for validation\n",
    "df_train, df_val = sklearn.model_selection.train_test_split(df_train, test_size=0.20, random_state=1 , stratify=df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 51509, 'test': 11363, 'val': 12878, 'eval': 25250}\n"
     ]
    }
   ],
   "source": [
    "print ({\"train\": len(df_train), \"test\":len(df_test), \"val\":len(df_val) ,\"eval\": len(df_eval)  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_transforms = flash.image.classification.transforms.default_transforms((224, 224))\n",
    "default_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_tensor_transform = ApplyToKeys(\n",
    "    DefaultDataKeys.INPUT,\n",
    "    T.Compose([T.RandomHorizontalFlip(), T.ColorJitter(), T.RandomAutocontrast(), T.RandomPerspective()]),\n",
    ")\n",
    "\n",
    "new_transforms = merge_transforms(default_transforms, {\"post_tensor_transform\": post_tensor_transform})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule = ImageClassificationData.from_data_frame(\n",
    "#     \"file_path\",\n",
    "#     \"label\",\n",
    "#     train_data_frame=df_train,\n",
    "#     val_data_frame=df_val,\n",
    "#     test_data_frame=df_test,\n",
    "#     train_transform=new_transforms\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.delete_non_persistent_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_fiftyone_dataset (df_train,\"train\")\n",
    "val_dataset = create_fiftyone_dataset (df_val,\"validation\") \n",
    "test_dataset = create_fiftyone_dataset (df_test,\"test\")\n",
    "eval_dataset = create_fiftyone_dataset (df_eval,\"eval\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = flash.image.ImageClassificationData.from_fiftyone(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    train_transform=new_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = \"data/food-101-subset/images/apple_pie/1005649.jpg\"\n",
    "strategy=\"dp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input_size = (1, 3, 224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_inference(model,device='cpu'):\n",
    "    model = model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.to(device)\n",
    "        predictions = model.predict(sample_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name:str, epochs = 2, unfreeze_epoch = 5 ,num_iterations=10, df_eval=df_eval  ):\n",
    "    model = flash.image.ImageClassifier(num_classes=datamodule.num_classes,backbone=model_name)\n",
    "    print (f\"Model Spec: {model_name}\")\n",
    "    print(model)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print (\"Model Summary\")\n",
    "    \n",
    "    model_summary = torchinfo.summary(model, input_size=sample_input_size, verbose=0)\n",
    "    print (model_summary)\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    \n",
    "    trainer = flash.Trainer(max_epochs=epochs, gpus=torch.cuda.device_count() , strategy=strategy)\n",
    "\n",
    "    \n",
    "    \n",
    "    trainer.finetune(model, datamodule=datamodule\n",
    "                 , strategy=flash.core.finetuning.FreezeUnfreeze(unfreeze_epoch=unfreeze_epoch) )\n",
    "    \n",
    "    \n",
    "    metrics_test = trainer.test(model, datamodule=datamodule)\n",
    "    print (metrics_test)\n",
    "\n",
    "    \n",
    "    metrics_val =trainer.validate(model, datamodule=datamodule)\n",
    "    print(metrics_val)\n",
    "    \n",
    "    artifact_model_path = f\"artifacts/model_{model_name}.pt\"\n",
    "    trainer.save_checkpoint(artifact_model_path)\n",
    "\n",
    "    model = flash.image.ImageClassifier.load_from_checkpoint(artifact_model_path)\n",
    "    \n",
    "    time_gpu = timeit.timeit(lambda: time_inference (model,device='cuda:0') ,number=num_iterations   ) \n",
    "    time_cpu = timeit.timeit(lambda: time_inference (model,device='cpu') ,number=num_iterations   ) \n",
    "    \n",
    "    \n",
    "    # eval dataset accuracy\n",
    "    eval_dataset = create_fiftyone_dataset (df_eval,\"eval\")\n",
    "    datamodule_eval = flash.image.ImageClassificationData.from_fiftyone(predict_dataset=eval_dataset)\n",
    "    predictions = trainer.predict(model, datamodule=datamodule_eval) # datamodule_predict\n",
    "    predictions = list(itertools.chain.from_iterable(predictions))  # flatten batches\n",
    "    y_proba = predictions\n",
    "    y_pred = np.argmax(y_proba, axis=1)\n",
    "    y_true = df_test['label']\n",
    "\n",
    "    eval_accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    \n",
    "    \n",
    "    res = {**metrics_test[0], **metrics_val[0]}\n",
    "    res['time_cpu'] = time_cpu\n",
    "    res['time_gpu'] = time_gpu\n",
    "    res['eval_accuracy'] = eval_accuracy\n",
    "    \n",
    "    res['params_total'] = model_summary.total_params\n",
    "    res['params_trainable'] = model_summary.trainable_params\n",
    "    \n",
    "\n",
    "\n",
    "    model_metrics[model_name] = res\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 30\n",
    "unfreeze_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = flash.Trainer(max_epochs=max_epochs, gpus=torch.cuda.device_count(), strategy=strategy  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vgg19'\n",
    "model = train_model(model_name=model_name, epochs = max_epochs, unfreeze_epoch = unfreeze_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model_name='resnet50', epochs = max_epochs, unfreeze_epoch = unfreeze_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model_name='mobilenet_v2', epochs = max_epochs, unfreeze_epoch = unfreeze_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model_name='mobilenetv3_small_100', epochs = max_epochs, unfreeze_epoch = unfreeze_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"artifacts/model_metrics.json\") as f:\n",
    "    payload = json.dumps(model_metrics)\n",
    "    f.write(payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(\"artifacts/data/df_train.parquet\")\n",
    "df_test.to_parquet(\"artifacts/data/df_test.parquet\")\n",
    "df_val.to_parquet(\"artifacts/data/df_val.parquet\")\n",
    "df_eval.to_parquet(\"artifacts/data/adf_eval.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenet_v2\"\n",
    "artifact_model_path = f\"artifacts/model_{model_name}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = flash.image.ImageClassifier.load_from_checkpoint(artifact_model_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary = torchinfo.summary(model, input_size=sample_input_size, verbose=0)\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.serializer = flash.core.classification.Probabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\"data/food-101-subset/images/apple_pie/1005649.jpg\")\n",
    "predictions\n",
    "#label_encoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted ( zip (label_encoder.classes_, predictions[0]), key= lambda x:x[1] ,reverse =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule_predict = ImageClassificationData.from_data_frame(\n",
    "#     \"file_path\",\n",
    "#     \"label\",\n",
    "#     test_data_frame=df_test,\n",
    "#     predict_transform=default_transforms\n",
    "# )\n",
    "# datamodule_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?flash.core.classification.PredsClassificationSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.serializer = flash.core.classification.PredsClassificationSerializer()\n",
    "# fo_predict = create_fiftyone_dataset(df_test,\"predict\")\n",
    "# datamodule_predict = ImageClassificationData.from_fiftyone(fo_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.serializer = flash.core.classification.FiftyOneLabels(return_filepath=False, labels=label_encoder.classes_)  # output FiftyOne format\n",
    "fo_predict = create_fiftyone_dataset(df_eval,\"predict\")\n",
    "datamodule_predict = flash.image.ImageClassificationData.from_fiftyone(predict_dataset=fo_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(model, datamodule=datamodule_predict) # datamodule_predict\n",
    "predictions = list(itertools.chain.from_iterable(predictions))  # flatten batches\n",
    "\n",
    "fo_predict.set_values(\"predictions\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fo_predict.evaluate_classifications(\"predictions\", gt_field=\"ground_truth\", eval_key=\"eval\")\n",
    "results.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = results.plot_confusion_matrix(classes=label_encoder.classes_)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Visualize results in the App\n",
    "session = fo.launch_app(fo_predict, auto=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.open_tab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ip a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot = results.plot_confusion_matrix(classes=label_encoder.classes_)\n",
    "plot.show(height=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to session\n",
    "#session.plots.attach(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: block execution until App is closed\n",
    "# session.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.serializer = flash.core.classification.Probabilities()\n",
    "\n",
    "predictions = trainer.predict(model,datamodule=datamodule_predict)\n",
    "predictions = list(itertools.chain.from_iterable(predictions))  # flatten batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_proba = model.predict(list ( df_test['file_path'] ) )\n",
    "# y_pred = np.argmax(y_proba, axis=1)\n",
    "# y_true = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = predictions\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "y_true = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/60860121/plotly-how-to-make-an-annotated-confusion-matrix-using-a-heatmap\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "cm_labels = label_encoder.classes_\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true=y_true, y_pred = y_pred ,\n",
    "    #normalize = 'true',\n",
    "    display_labels=cm_labels,\n",
    "    xticks_rotation='vertical',\n",
    "    ax=ax\n",
    ")\n",
    "disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = \"data/food-101-subset/images/apple_pie/1005649.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_inference' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20720/3135351056.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-r 9 -n 5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time_inference (model,device='cuda:0')\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/pytorch/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2404\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2406\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2407\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch/lib/python3.7/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time_inference' is not defined"
     ]
    }
   ],
   "source": [
    "%%timeit -r 9 -n 5\n",
    "time_inference (model,device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 9 -n 5\n",
    "time_inference (model,device='cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk6M8HvofvTR"
   },
   "source": [
    "# Get Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWPA6uYlUyBV"
   },
   "outputs": [],
   "source": [
    "! du -h artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbIPxgoN3zvd"
   },
   "outputs": [],
   "source": [
    "!ls artifacts/ -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bILr-eFU-wUG"
   },
   "source": [
    "# Compare Models\n",
    "\n",
    "- Dataset:  Food\n",
    "- Classes: 3\n",
    "- Total images: 3000\n",
    "- Batch size: 32\n",
    "\n",
    "| Model  | Trainable Params| Non-trainable Params | Time (hh:mm:ss) [a]| Accuracy | Epochs | Model Size [b]\n",
    "|---|---:|---:|---:|---:| ---:|---:|\n",
    "| VGG19| 528,387   | 20,024,384 | 00:00:48 | 96.8% | 3 | 83M\n",
    "| ResNet50   | xxx   | xxx |  xx:xx:xx | xx.x% | 3 | xxM\n",
    "| MobileNetV2  | xxx  | xxx |   xx:xx:xx | xx.x% | 3 | xxM\n",
    "| ResNet50_ft [c]  | xxx  | xxx | xx:xx:xx   | xx.x% | xx | xxM\n",
    "\n",
    "NOTES:  \n",
    "- [a] If wall clock time < CPU time, then you're executing a program in parallel.\n",
    "- [b] model size is size of output file\n",
    "- [c] ft = fine-tuned; time 2min 31s; 3min 59s; epochs 9+5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CU9ACHvSIEnZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVz7Xf40tPPP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh76dgMeVIDD"
   },
   "source": [
    "# Download Assets\n",
    "download model and classes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqxTNOVCoHCc"
   },
   "outputs": [],
   "source": [
    "#!zip -r artifacts/artifacts.zip {PROJECT_NAME}/artifacts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63KIL2HndL-c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.download(str(str(PROJECT_NAME)+\"/artifacts/artifacts.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVrj_UAD-xDr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "milestone1_partial_solution_3classes.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "rapids-gpu.0-18.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/rapids-gpu.0-18:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
