{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2jji3LQ0LAp"
   },
   "source": [
    "# Manning liveProject: Deploy DL Model on Web & Mobile Using TensorFlow\n",
    "---\n",
    "## Milestone 1: Build an image classifier\n",
    "## Partial Solutions Notebook\n",
    "---\n",
    "#### Date updated:  02-March-2021\n",
    "#### Author:  Nidhin Pattaniyil & Reshama Shaikh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LRWAJYt4jv8"
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "current_date = date.today()\n",
    "print(\"Today's date:\", current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1Y5mbjxwm_-"
   },
   "outputs": [],
   "source": [
    "now1 = datetime.now()\n",
    "\n",
    "start_time = now1.strftime(\"%H:%M:%S\")\n",
    "print(\"Start Time =\", start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gs5vb902xRNC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KM5tPUJ-xUxT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFh12cb80zbE"
   },
   "outputs": [],
   "source": [
    "# run this once (each session) if `watermark` library is not loaded, then comment out\n",
    "!pip install watermark tensorflow==2.3.* -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KF2VkBMxzqmr"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import glob\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import pprint\n",
    "import json\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgQANa-S0gAQ"
   },
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFtsAWFB4887"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiMSleV30kAE"
   },
   "outputs": [],
   "source": [
    "import watermark\n",
    "%load_ext watermark\n",
    "#%reload_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbstfaBp0qR1"
   },
   "outputs": [],
   "source": [
    "# see version of system, python and libraries\n",
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdGngfwTb-LH"
   },
   "outputs": [],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEqdRy-jl_7K"
   },
   "source": [
    "# Running GPU on Colab\n",
    "Ensure that GPU is running on this Colab notebook by following below steps.\n",
    "1. Colab Menu: Select \"Runtime\"\n",
    "2. \"Change runtime type\"\n",
    "3. Select \"Hardware Accelerator\" = GPU\n",
    "4. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDISycD15Z0J"
   },
   "outputs": [],
   "source": [
    "# confirm that GPU is running\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cd-AUp875hQP"
   },
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twHKZbDln0Rw"
   },
   "source": [
    "# Setup Project Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JqBBSuGnJqj"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nq0oWuqfp1Bt"
   },
   "outputs": [],
   "source": [
    "!ls -lF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aULYc0cdn4P4"
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"project_food_dl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Z1kAeYv1XLt"
   },
   "outputs": [],
   "source": [
    "# create a sub-directory for the data\n",
    "# run this once and comment out\n",
    "!mkdir -p {PROJECT_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z03s6v80oOxy"
   },
   "outputs": [],
   "source": [
    "!ls -lF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJuUSZjtWH75"
   },
   "outputs": [],
   "source": [
    "!ls -lF {PROJECT_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LjF61RUWS6V"
   },
   "outputs": [],
   "source": [
    "# remove log files from models\n",
    "!rm -rf {PROJECT_NAME}/artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRLwRz78WkJK"
   },
   "outputs": [],
   "source": [
    "!rm -rf {PROJECT_NAME}/data/food-101.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HX3Kz2FvYPDM"
   },
   "outputs": [],
   "source": [
    "!rm -f artifacts.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6yPDTs4mxg3"
   },
   "outputs": [],
   "source": [
    "# create a sub-directory for data\n",
    "!mkdir -p {PROJECT_NAME}/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ucUB9MQoiF9"
   },
   "outputs": [],
   "source": [
    "!ls {PROJECT_NAME} -lF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYgWLloApHWI"
   },
   "source": [
    "Artifacts is common ML term used to describe the output created by the training process.\n",
    "\n",
    "The output could be a fully trained model, a model checkpoint (for resuming training later), or simply a file created during the training process such as an image generated while training a Generative Adversarial Network (GAN).  \n",
    "In the case of a Deep Learning model, the model artifacts are the trained weights stored in a binary format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTWGkG26ok36"
   },
   "outputs": [],
   "source": [
    "# create a sub-directory for artifacts\n",
    "!mkdir -p {PROJECT_NAME}/artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_x5OW_dowRr"
   },
   "outputs": [],
   "source": [
    "!ls {PROJECT_NAME} -lF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ou6WJYn28B_B"
   },
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFzm8-JUiLiB"
   },
   "outputs": [],
   "source": [
    "! wget https://lp-prod-resources.s3-us-west-2.amazonaws.com/other/Deploying+a+Deep+Learning+Model+on+Web+and+Mobile+Applications+Using+TensorFlow/Food+101+-+Data+Subset.zip -P {PROJECT_NAME}/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stqqJc561hxH"
   },
   "outputs": [],
   "source": [
    "# unpack the data\n",
    "# run only once, then comment out \n",
    "\n",
    "!unzip -q {PROJECT_NAME}/data/Food+101+-+Data+Subset.zip -d {PROJECT_NAME}/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRKI5sT3SFtP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltGPhCJutcK6"
   },
   "outputs": [],
   "source": [
    "!ls {PROJECT_NAME} -lF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVzHTT4Y8YBx"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = str(PROJECT_NAME)+\"/data/food-101-subset/images\"\n",
    "DATA_DIR = pathlib.Path(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFkyQkfcSQn2"
   },
   "outputs": [],
   "source": [
    "!rm -rf {DATA_DIR}/.DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqZKhFwR8bDW"
   },
   "outputs": [],
   "source": [
    "DATA_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojoU1UKa3t77"
   },
   "source": [
    "# Look at dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4vZy2ti30eX"
   },
   "outputs": [],
   "source": [
    "# look at folder names\n",
    "!ls -lah {DATA_DIR}/ | head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkZmKmUG30qB"
   },
   "outputs": [],
   "source": [
    "# look at first five images in first image folder\n",
    "!ls {DATA_DIR}/apple_pie | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2h1HfkCn304h"
   },
   "outputs": [],
   "source": [
    "# find out how many total images there are in database\n",
    "image_count = len(list(DATA_DIR.glob('*/*.jpg')))\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "biXjyk-VvrGP"
   },
   "outputs": [],
   "source": [
    "# find out how many different classes there are\n",
    "ALL_CLASS_NAMES = sorted(np.array([item.name for item in DATA_DIR.glob('*')]))\n",
    "print(len(ALL_CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLaB5XjClydq"
   },
   "outputs": [],
   "source": [
    "ALL_CLASS_NAMES[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67sN9AFCl-i9"
   },
   "outputs": [],
   "source": [
    " USE_CLASS_NAMES = ALL_CLASS_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqKpCtdOzx-1"
   },
   "source": [
    "# Look at Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOSInJ44So4o"
   },
   "outputs": [],
   "source": [
    "class1 = ALL_CLASS_NAMES[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DttFFRdw91st"
   },
   "outputs": [],
   "source": [
    "images = list(DATA_DIR.glob(f'{class1}/*'))\n",
    "\n",
    "for image_path in images[:2]:\n",
    "    # resize image\n",
    "    im = Image.open(str(image_path))\n",
    "    w, h = im.size\n",
    "    print('Image Size (w, h): ', w, \",\",  h)\n",
    "    print (image_path)\n",
    "    percent_resize = 0.5\n",
    "    im = im.resize((int(w*percent_resize), int(h*percent_resize)))\n",
    "    display.display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNlINYE6p0Qy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-Jx2g1O4KeW"
   },
   "source": [
    "# Setup for Training Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoQAk1Nve5QJ"
   },
   "source": [
    "The `ImageDataGenerator` is used to create training and validation splits.\n",
    "It also has several builtin image preprocessing transformations. \n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WkldTMyp7oG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ylce5nhbiV1U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xrBJfMXXqY01"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jxbLtBnqpAk"
   },
   "outputs": [],
   "source": [
    "print(\"Number of classes we are training: \" ,len(USE_CLASS_NAMES))\n",
    "print(\"\\nList of classes\")\n",
    "list(USE_CLASS_NAMES)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOYFUXQ9qqnS"
   },
   "outputs": [],
   "source": [
    "# create a data generator object with options (location of images, batch size, option to shuffle, etc)\n",
    "def get_image_data_generator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input ):\n",
    "  image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=preprocessing_function\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  # create a data generator object with options (location of images, batch size, option to shuffle, etc)\n",
    "  image_data_gen = image_generator.flow_from_directory(\n",
    "      directory=str(DATA_DIR),\n",
    "      batch_size=BATCH_SIZE,\n",
    "      shuffle=True,\n",
    "      target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "      classes = list(USE_CLASS_NAMES)\n",
    "      )\n",
    "\n",
    "  return image_data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzQY4Bc3ij3s"
   },
   "outputs": [],
   "source": [
    "image_data_gen = get_image_data_generator (preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hzo_Ksmijwd"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-VZbiM9MDuh"
   },
   "source": [
    "# Save list of classes as `classes.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgpsH0i6rDW-"
   },
   "outputs": [],
   "source": [
    "image_data_gen.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFmz5pkNKpz1"
   },
   "outputs": [],
   "source": [
    "image_data_gen.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqHkvoFzLFA7"
   },
   "outputs": [],
   "source": [
    "list_of_classes = list(image_data_gen.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfwjwtgdLJey"
   },
   "outputs": [],
   "source": [
    "list_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5NSurxMchjB"
   },
   "outputs": [],
   "source": [
    "with open(f\"{PROJECT_NAME}/artifacts/classes.json\",'w') as f:\n",
    "  json.dump(list_of_classes,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0K-dkX_Jgn0R"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJmGNuk5I4WW"
   },
   "source": [
    "# Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnjozD71JVTK"
   },
   "source": [
    "### Model 1:  VGG19 (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "teQJB_MfhBUs"
   },
   "outputs": [],
   "source": [
    "?tf.keras.layers.Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXwbP2cXsNqD"
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "# Use VGG19 pretrained on ImageNet\n",
    "base_layers = tf.keras.applications.VGG19(weights='imagenet',include_top=False,input_shape=IMAGE_SHAPE+(3,) )\n",
    "\n",
    "# Add new layers to be finetuned\n",
    "# The last layer, is the classification layer and should match the number of classes in the dataset. The activation should be softmax \n",
    "clf = tf.keras.Sequential([\n",
    "    base_layers\n",
    "    , tf.keras.layers.GlobalAveragePooling2D()\n",
    "    , tf.keras.layers.Dense(1024, activation='relu')\n",
    "    , tf.keras.layers.Dense(image_data_gen.num_classes , name='classification', activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IitJEFKIJfJp"
   },
   "outputs": [],
   "source": [
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_JiW81Bn-aJ"
   },
   "outputs": [],
   "source": [
    "# freezes the base layers\n",
    "base_layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vC2ZF_P6n_2H"
   },
   "outputs": [],
   "source": [
    "# notice that after freezing the base layers, the non trainable params are equal to the number of parameters in the base layer \n",
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WK7-iAksvn0s"
   },
   "outputs": [],
   "source": [
    "# Set the model to use Adam optimizer , cross entropy loss, and track accuracy.\n",
    "# Since the dataset has multiple classes, we are using cross entropy loss.\n",
    "clf.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss='categorical_crossentropy' ,\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_WTnlVE7pai"
   },
   "source": [
    "#### Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GNh8DMgvoKH"
   },
   "outputs": [],
   "source": [
    "# train the model for 3 epochs\n",
    "%%time\n",
    "# Note the preprocessing function uses the preprocessing function for vgg19. You should replace this line for other models\n",
    "image_data_gen = get_image_data_generator (preprocessing_function=tf.keras.applications.vgg19.preprocess_input)\n",
    "\n",
    "history = clf.fit(image_data_gen\n",
    "                        ,epochs=3\n",
    "                        ,workers=8 \n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0oRWUc7LORx"
   },
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6M1HibRJHBWq"
   },
   "outputs": [],
   "source": [
    "# save the model as `h5` format\n",
    "export_path = str(PROJECT_NAME)+\"/artifacts/model_VGG19.h5\"\n",
    "export_path\n",
    "clf.save(export_path, save_format='h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dE6YQT0mPgk"
   },
   "source": [
    "### Model 2:  ResNet50\n",
    "On your own, train a model using ResNet50.  \n",
    "\n",
    "Don't forget to use the right preprocessing function when creating the data generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsF-EVy9Jlcv"
   },
   "source": [
    "### Model 3: MobileNetV2 (Final)\n",
    "On your own, train a model using MobileNetV2.\n",
    "\n",
    "Don't forget to use the right preprocessing function when creating the data generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG1yctSYSKTP"
   },
   "source": [
    "## Fine tune model (OPTIONAL)\n",
    "\n",
    "The model accuracy can be further improved by \n",
    "- unfreezing the early layers, use [transfer learning](https://www.tensorflow.org/guide/keras/transfer_learning)\n",
    "- use [data augmentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMc4g4VJw9hA"
   },
   "source": [
    "# Time to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqKB6VX3Ssf8"
   },
   "outputs": [],
   "source": [
    "now2 = datetime.now()\n",
    "\n",
    "end_time = now2.strftime(\"%H:%M:%S\")\n",
    "print(\"End Time =\", end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eThpapNJxDET"
   },
   "outputs": [],
   "source": [
    "diff2=((now2-now1).total_seconds() )/ (60)\n",
    "print(\"Time to run (minutes): \", diff2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk6M8HvofvTR"
   },
   "source": [
    "# Get Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWPA6uYlUyBV"
   },
   "outputs": [],
   "source": [
    "! du -h {PROJECT_NAME}/artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbIPxgoN3zvd"
   },
   "outputs": [],
   "source": [
    "!ls {PROJECT_NAME}/artifacts/ -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bILr-eFU-wUG"
   },
   "source": [
    "# Compare Models\n",
    "\n",
    "- Dataset:  Food\n",
    "- Classes: 3\n",
    "- Total images: 3000\n",
    "- Batch size: 32\n",
    "\n",
    "| Model  | Trainable Params| Non-trainable Params | Time (hh:mm:ss) [a]| Accuracy | Epochs | Model Size [b]\n",
    "|---|---:|---:|---:|---:| ---:|---:|\n",
    "| VGG19| 528,387   | 20,024,384 | 00:00:48 | 96.8% | 3 | 83M\n",
    "| ResNet50   | xxx   | xxx |  xx:xx:xx | xx.x% | 3 | xxM\n",
    "| MobileNetV2  | xxx  | xxx |   xx:xx:xx | xx.x% | 3 | xxM\n",
    "| ResNet50_ft [c]  | xxx  | xxx | xx:xx:xx   | xx.x% | xx | xxM\n",
    "\n",
    "NOTES:  \n",
    "- [a] If wall clock time < CPU time, then you're executing a program in parallel.\n",
    "- [b] model size is size of output file\n",
    "- [c] ft = fine-tuned; time 2min 31s; 3min 59s; epochs 9+5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_gyW7wtzt5W"
   },
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-6r0UL5Z-ZB"
   },
   "outputs": [],
   "source": [
    "model_path_vgg19 = str(PROJECT_NAME)+\"/artifacts/model_VGG19.h5\"\n",
    "clf_final = tf.keras.models.load_model(model_path_vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEO425ndbBS7"
   },
   "outputs": [],
   "source": [
    "with open(f\"{PROJECT_NAME}/artifacts/classes.json\",'r') as f:\n",
    "  list_of_classes = json.load(f)\n",
    "  #content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvrcsqSmbYac"
   },
   "outputs": [],
   "source": [
    "list_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWK6eUGw5T4n"
   },
   "outputs": [],
   "source": [
    "# if you want to delete a directory from past runs\n",
    "!rm -rf {PROJECT_NAME}/test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUnud1rfurW-"
   },
   "outputs": [],
   "source": [
    "# create a sub-directory for data\n",
    "!mkdir -p {PROJECT_NAME}/test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-z52JLTZQMb"
   },
   "outputs": [],
   "source": [
    "!wget https://natashaskitchen.com/wp-content/uploads/2019/01/Caesar-Salad-Recipe-3.jpg -P {PROJECT_NAME}/test_image -O {PROJECT_NAME}/test_image/caesar_salad.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CsZJ0GOBHVQ_"
   },
   "outputs": [],
   "source": [
    "!wget https://upload.wikimedia.org/wikipedia/commons/9/99/Black_square.jpg -P {PROJECT_NAME}/test_image -O {PROJECT_NAME}/test_image/black_square.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbYvKQOzGfRO"
   },
   "outputs": [],
   "source": [
    "# \n",
    "!wget https://image.shutterstock.com/image-photo/brown-light-wooden-round-dining-260nw-588358070.jpg -P {PROJECT_NAME}/test_image  -O {PROJECT_NAME}/test_image/table.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0nAfbdGHfDV"
   },
   "outputs": [],
   "source": [
    "img_path = f\"{PROJECT_NAME}/test_image/caesar_salad.jpg\"\n",
    "#img_path = f\"{PROJECT_NAME}/test_image/table.jpg\"\n",
    "#img_path = f\"{PROJECT_NAME}/test_image/black_square.jpg\"\n",
    "\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLM5JxwEsih9"
   },
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image.load_img(img_path, target_size = (IMG_HEIGHT, IMG_WIDTH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Eynl7n2simr"
   },
   "outputs": [],
   "source": [
    "def load_img_predict(img_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size = (IMG_HEIGHT, IMG_WIDTH))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = tf.keras.applications.vgg19.preprocess_input(img)\n",
    "\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOfTwls9jJKW"
   },
   "outputs": [],
   "source": [
    "#classifier = classifier['MobileNetV2']\n",
    "#classifier = classifier['VGG19']\n",
    "clf_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xyUQ-MxsoNN"
   },
   "outputs": [],
   "source": [
    "def predict_image(img_path,classifier):\n",
    "    img = load_img_predict(img_path)\n",
    "    res = clf_final.predict(img)\n",
    "\n",
    "    res = sorted (\n",
    "        list(zip ( \n",
    "            list_of_classes\n",
    "            , np.squeeze(res)\n",
    "         )\n",
    "        )\n",
    "     , key=lambda x: x[1]   \n",
    "     , reverse=True\n",
    "    )\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSU62bAHsoUt"
   },
   "outputs": [],
   "source": [
    "predict_image(img_path,clf_final)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CU9ACHvSIEnZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVz7Xf40tPPP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh76dgMeVIDD"
   },
   "source": [
    "# Download Assets\n",
    "download model and classes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqxTNOVCoHCc"
   },
   "outputs": [],
   "source": [
    "!zip -r {PROJECT_NAME}/artifacts/artifacts.zip {PROJECT_NAME}/artifacts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63KIL2HndL-c"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(str(str(PROJECT_NAME)+\"/artifacts/artifacts.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVrj_UAD-xDr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "milestone1_partial_solution_3classes.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "rapids-gpu.0-18.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/rapids-gpu.0-18:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
